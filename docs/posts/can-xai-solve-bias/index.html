<!doctype html><html lang=en-us data-anim=none><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>alvise.xyz/posts/can-xai-solve-bias/</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><link rel=stylesheet href=/main.min.6189384835c79642de704d6c757f3103b15e0d3c40274ec2c9462f38c033cb2a.css media=all><script type=text/javascript>var storedTheme=localStorage.getItem('theme')||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");if(storedTheme){document.documentElement.setAttribute('data-theme',storedTheme)}</script><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script><script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><meta property="og:title" content="AI Explanation: what the hell is even that?"><meta property="og:description" content><meta property="og:type" content="article"><meta property="og:url" content="https://www.alvise.xyz/posts/can-xai-solve-bias/"><meta property="og:image" content="https://www.alvise.xyz/posts/can-xai-solve-bias/img/ml_hu711e1ee2b9b6b0bd24ce1182739eb66b_41184_400x0_resize_q75_box.jpg"><meta property="article:published_time" content="2022-07-07T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.alvise.xyz/posts/can-xai-solve-bias/img/ml_hu711e1ee2b9b6b0bd24ce1182739eb66b_41184_400x0_resize_q75_box.jpg"><meta name=twitter:title content="AI Explanation: what the hell is even that?"><meta name=twitter:description content="During my last year of university I wrote a short paper on AI explanation as part of the final examination for the Phylosophical Issues in Computer Science course. Although this is definitely not my main field of expertise, I found that reading and reflecting on the problem of giving people a right for an explanation and trying to understand and eliminate the bias that we&mldr;"></head><body class=terminal><div class="container top-container"><div class=terminal-nav><header class=terminal-logo><div class="logo terminal-prompt"><a href=https://www.alvise.xyz/ class=no-style>alvise.xyz</a>:~/$</div></header><nav class=terminal-menu><ul vocab="https://schema.org/" typeof="BreadcrumbList"><li><a href=https://www.alvise.xyz/about/ typeof="ListItem">about/</a></li><li><span class=separator></span></li><li><button id=theme-toggle>ðŸŒ“ï¸Ž</button></li></ul></nav></div></div><div class=header-spacer></div><div class="container main-container animated fadeInUp faster"><h1 class=post-title>AI Explanation: what the hell is even that?</h1><div class=post-content><figure><img src=img/ml.jpg.webp alt="Machine Learning Memes for Convolutional Teens"><figcaption><p>Machine Learning Memes for Convolutional Teens</p></figcaption></figure><p>During my last year of university I wrote a short paper on AI explanation as part of the final examination for the <em>Phylosophical Issues in Computer Science</em> course. Although this is definitely not my main field of expertise, I found that reading and reflecting on the problem of giving people a right for an explanation and trying to understand and eliminate the bias that we, as humans, introduce in AI systems is a very fascinating topic, and probably something that has no clear solution.</p><p>In this short paper I introduce some of the main concepts of XAI (eXplainable AI) that I found in the current literature, and I present a small thought experiment to make the case that explanation interfaces can&rsquo;t per-se eliminate bias, and they can actually make the problem worse by framing the explanation in the right way.</p><p>So, if youâ€™re interested in a reflection on the opportunities (and possible risks) of AI explanation, <a href=https://raw.githubusercontent.com/AlviseDeFaveri/XAI-paper/master/main.pdf>here</a> you go. I&rsquo;m not an expert, so consider yourself warned.</p><div class=repo-card data-repo=AlviseDeFaveri/XAI-paper onclick="location.href='https://github.com/AlviseDeFaveri\/XAI-paper'">Loading Github repo ...</div><p>Have a good one!</p><p>~A</p></div><footer class=footer><p>Â© 2022 Alvise de Faveri Tron
//
Built using
<a href=https://gohugo.io/>Hugo</a>, theme based on
<a href=https://github.com/mrmierzejewski/hugo-theme-console/>Console</a></p></footer></div></body><script type=text/javascript src=/js/repo-card.js></script><script type=text/javascript>var toggle=document.getElementById("theme-toggle");toggle.onclick=function(){document.documentElement.setAttribute("data-anim","fast")
var currentTheme=document.documentElement.getAttribute("data-theme");var targetTheme=currentTheme==="light"?"dark":"light";document.documentElement.setAttribute("data-theme",targetTheme)
localStorage.setItem("theme",targetTheme);};</script></html>